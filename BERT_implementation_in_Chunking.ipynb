{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT implementation in Chunking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO+iRjscoNISh6pM0s8B8IU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b494f950771a4daa8ead52747caf30cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3446c38cba0f4128bad9fa39f795d323",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0405d3e14464a97891a58d966daa7b0",
              "IPY_MODEL_e9b2396950214441a8eef7c6e775b964"
            ]
          }
        },
        "3446c38cba0f4128bad9fa39f795d323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0405d3e14464a97891a58d966daa7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98676a5cf3ac4ef8ab1d3d246a48198b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b049e7bb7604e4f8fb558f90aea2cf8"
          }
        },
        "e9b2396950214441a8eef7c6e775b964": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1bc5b417c3e645a0ac7fda817d4854e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 3.00MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4d37816f6a64a7da39c85d8a299def7"
          }
        },
        "98676a5cf3ac4ef8ab1d3d246a48198b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b049e7bb7604e4f8fb558f90aea2cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1bc5b417c3e645a0ac7fda817d4854e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4d37816f6a64a7da39c85d8a299def7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc9510e9a5c94b3d8f0d8fa7556903e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f97fd85d1e4e47cd93980e61e8dcc7c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f3a6d28bd5d4f3ebbd6809b0d9a96c7",
              "IPY_MODEL_5f6b0003fb6e4e5bacaf8634588e74e3"
            ]
          }
        },
        "f97fd85d1e4e47cd93980e61e8dcc7c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f3a6d28bd5d4f3ebbd6809b0d9a96c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2691d2f090e54f5da090ab248772b258",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a6180aad4fd4b5fb54154c535c05113"
          }
        },
        "5f6b0003fb6e4e5bacaf8634588e74e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_224b5987a7524a9584b5590f39b68b7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 411/411 [00:00&lt;00:00, 2.75kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d440783ef4534d608f6338098a428605"
          }
        },
        "2691d2f090e54f5da090ab248772b258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a6180aad4fd4b5fb54154c535c05113": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "224b5987a7524a9584b5590f39b68b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d440783ef4534d608f6338098a428605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e395e9cf61e474d8d299a2635f78f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1cbacf7dcc44930aaaf5c26ad7d3108",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31b5fe561714457d89e457af173757a0",
              "IPY_MODEL_66d1dfa6194a4a15854e255693008c01"
            ]
          }
        },
        "d1cbacf7dcc44930aaaf5c26ad7d3108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31b5fe561714457d89e457af173757a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_63517e572f9447dfb890f35fe6175aa9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263273408,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263273408,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffa1fbfd56dc44f28ed54fb9aac97ff1"
          }
        },
        "66d1dfa6194a4a15854e255693008c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8714962efb064391a9a913aeacb6aaf2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 263M/263M [00:05&lt;00:00, 52.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac231fd44bd74fab82c4833bede98fbe"
          }
        },
        "63517e572f9447dfb890f35fe6175aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffa1fbfd56dc44f28ed54fb9aac97ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8714962efb064391a9a913aeacb6aaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac231fd44bd74fab82c4833bede98fbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nadyadtm/BERT-Implementation-in-Chunking/blob/main/BERT_implementation_in_Chunking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B9vkPE8wCbB"
      },
      "source": [
        "# BERT implementation in Chunking\r\n",
        "\r\n",
        "Berikut ini adalah implementasi BERT untuk kasus Chunking. Dataset yang digunakan adalah dataset CONLL 2000 \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzgC6zWPwHev"
      },
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZuRmoCW1vyv",
        "outputId": "5463009c-310d-4fd3-df2e-37054308996c"
      },
      "source": [
        "# mount google drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBKHZxCVCrl2"
      },
      "source": [
        "## Import Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiFVlKIHCuoc",
        "outputId": "a14b19a9-7e04-4938-d096-b95adff435c1"
      },
      "source": [
        "#install package transformes dan lakukan import\r\n",
        "!pip install transformers==3\r\n",
        "import transformers\r\n",
        "from transformers import DistilBertModel, DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "\r\n",
        "#import package pytorch\r\n",
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset\r\n",
        "\r\n",
        "#import package sklearn\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "#import numpy, pandas\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#import os\r\n",
        "import os\r\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\r\n",
        "\r\n",
        "RANDOM_SEED = 42\r\n",
        "np.random.seed(RANDOM_SEED)\r\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 22.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=2acea75eecf05ac407ccdc96fecbe9e57f330402c04851efd546e3fa0c4ed2ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc8153482b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHD_07WS6SW3"
      },
      "source": [
        "##Set GPU\r\n",
        "Sebelum memulai pelatihan, perlu dilakukan set GPU untuk menjalankan Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FyHj5iP-ycS",
        "outputId": "14b95638-10fa-4263-d4d7-e5a25f12ec73"
      },
      "source": [
        "#mengecek apakah terdapat GPU pada komputer\r\n",
        "if torch.cuda.is_available():       \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\r\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\r\n",
        "#jika tidak ada maka gunakan CPU untuk menjalankan program\r\n",
        "else:\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuqvYIWjwK3D"
      },
      "source": [
        "## Load File txt\r\n",
        "Load train.txt dan test.txt terlebih dahulu, kemudian lakukan pengelompokkan kumpulan kata menjadi kumpulan kalimat dengan melihat tanda titiknya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OfU8wEa6wQ3"
      },
      "source": [
        "DATA_DIR = 'drive/My Drive/SMT 2/NLP/Tugas 3/Chunking/{}.txt'\r\n",
        "\r\n",
        "def get_data(file):\r\n",
        "    with open(file, 'r', encoding='latin1') as fp:\r\n",
        "        content = fp.readlines()\r\n",
        "    data, sent = [], []\r\n",
        "    for line in content:\r\n",
        "        if not line.strip():\r\n",
        "            if sent: data.append(sent)\r\n",
        "            sent = []\r\n",
        "        else:\r\n",
        "            word, pos, tag = line.strip().split()\r\n",
        "            # tag = tag.split('-')[0]\r\n",
        "            sent.append((word, pos, tag))\r\n",
        "    return data"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRfKj7V42oFk"
      },
      "source": [
        "train_data = get_data(DATA_DIR.format('train'))\r\n",
        "test_data = get_data(DATA_DIR.format('test'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFjvMU-Awlny"
      },
      "source": [
        "Kemudian, mengambil sentence dan label Tagnya. Dalam kasus ini label POS diabaikan\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzlEkeYNCg31"
      },
      "source": [
        "sentences = [[word[0] for word in sentence] for sentence in train_data]\r\n",
        "sentences_test = [[word[0] for word in sentence] for sentence in test_data]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCN10TwZj89u"
      },
      "source": [
        "labels = [[s[2] for s in sentence] for sentence in train_data]\r\n",
        "labels_test = [[s[2] for s in sentence] for sentence in test_data]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfB20UPFNIuP"
      },
      "source": [
        "Salah satu contoh kalimat dalam data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkbZ3zvGNNBq",
        "outputId": "522010e0-51b1-4465-cadc-8ade17a8f871"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Confidence',\n",
              " 'in',\n",
              " 'the',\n",
              " 'pound',\n",
              " 'is',\n",
              " 'widely',\n",
              " 'expected',\n",
              " 'to',\n",
              " 'take',\n",
              " 'another',\n",
              " 'sharp',\n",
              " 'dive',\n",
              " 'if',\n",
              " 'trade',\n",
              " 'figures',\n",
              " 'for',\n",
              " 'September',\n",
              " ',',\n",
              " 'due',\n",
              " 'for',\n",
              " 'release',\n",
              " 'tomorrow',\n",
              " ',',\n",
              " 'fail',\n",
              " 'to',\n",
              " 'show',\n",
              " 'a',\n",
              " 'substantial',\n",
              " 'improvement',\n",
              " 'from',\n",
              " 'July',\n",
              " 'and',\n",
              " 'August',\n",
              " \"'s\",\n",
              " 'near-record',\n",
              " 'deficits',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1A2q1tONQAM"
      },
      "source": [
        "Melihat maksimal jumlah kata dalam data train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFRn1mYcF4xY",
        "outputId": "ab8ae044-8c4b-429e-f8dd-65c9f7378d03"
      },
      "source": [
        "len_sentence = [len(s) for s in sentences]\r\n",
        "print(\"Jumlah kata maksimal dalam data: \", np.max(len_sentence))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jumlah kata maksimal dalam data:  78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8nw8He5xHOn"
      },
      "source": [
        "Daftar tag yang terdapat dalam dataset train dan test adalah sebagai berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPo9IsHZKNes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c4f94c-2f04-458a-cc68-ffb723b50f13"
      },
      "source": [
        "data1 = pd.read_csv(\"drive/My Drive/SMT 2/NLP/Tugas 3/Chunking/train.txt\", \r\n",
        "                  sep=' ', \r\n",
        "                  names=[\"Words\", \"POS\", \"Tag\"])\r\n",
        "data2 = pd.read_csv(\"drive/My Drive/SMT 2/NLP/Tugas 3/Chunking/test.txt\", \r\n",
        "                  sep=' ', \r\n",
        "                  names=[\"Words\", \"POS\", \"Tag\"])\r\n",
        "data = pd.concat([data1,data2])\r\n",
        "tag_values = list(set(data[\"Tag\"].values))\r\n",
        "tag_values.append(\"PAD\")\r\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}\r\n",
        "tag2idx"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-ADJP': 8,\n",
              " 'B-ADVP': 14,\n",
              " 'B-CONJP': 13,\n",
              " 'B-INTJ': 5,\n",
              " 'B-LST': 21,\n",
              " 'B-NP': 18,\n",
              " 'B-PP': 12,\n",
              " 'B-PRT': 9,\n",
              " 'B-SBAR': 6,\n",
              " 'B-UCP': 4,\n",
              " 'B-VP': 10,\n",
              " 'I-ADJP': 15,\n",
              " 'I-ADVP': 17,\n",
              " 'I-CONJP': 3,\n",
              " 'I-INTJ': 2,\n",
              " 'I-LST': 11,\n",
              " 'I-NP': 19,\n",
              " 'I-PP': 0,\n",
              " 'I-PRT': 1,\n",
              " 'I-SBAR': 22,\n",
              " 'I-UCP': 7,\n",
              " 'I-VP': 16,\n",
              " 'O': 20,\n",
              " 'PAD': 23}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugA89kmeLxZd"
      },
      "source": [
        "## Preprocessing\r\n",
        "Inisiasi Tokenizer, max len, dan batch size terlebih dahulu. Pada kasus ini, model yang digunakan DistilBert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPsvBRhVLQVJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "b494f950771a4daa8ead52747caf30cf",
            "3446c38cba0f4128bad9fa39f795d323",
            "f0405d3e14464a97891a58d966daa7b0",
            "e9b2396950214441a8eef7c6e775b964",
            "98676a5cf3ac4ef8ab1d3d246a48198b",
            "5b049e7bb7604e4f8fb558f90aea2cf8",
            "1bc5b417c3e645a0ac7fda817d4854e3",
            "c4d37816f6a64a7da39c85d8a299def7"
          ]
        },
        "outputId": "f9a0450b-13c7-465b-d6ac-5cfe2534fe54"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-cased'\r\n",
        "MAX_LEN = np.max(len_sentence)\r\n",
        "bs = 32\r\n",
        "\r\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b494f950771a4daa8ead52747caf30cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJuoQZ3Yxe7O"
      },
      "source": [
        "Fungsi tersebut digunakan untuk melakukan tokenisasi kalimat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4RV5Ih5lYen"
      },
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\r\n",
        "    tokenized_sentence = []\r\n",
        "    labels = []\r\n",
        "\r\n",
        "    for word, label in zip(sentence, text_labels):\r\n",
        "\r\n",
        "        # Tokenize the word and count # of subwords the word is broken into\r\n",
        "        tokenized_word = tokenizer.tokenize(word)\r\n",
        "        n_subwords = len(tokenized_word)\r\n",
        "\r\n",
        "        # Add the tokenized word to the final tokenized word list\r\n",
        "        tokenized_sentence.extend(tokenized_word)\r\n",
        "\r\n",
        "        # Add the same label to the new list of labels `n_subwords` times\r\n",
        "        labels.extend([label] * n_subwords)\r\n",
        "\r\n",
        "    return tokenized_sentence, labels"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2N7L0_vldiO"
      },
      "source": [
        "def tokenized(sentences,labels):\r\n",
        "    tokenized_texts_and_labels = [\r\n",
        "      tokenize_and_preserve_labels(sent, labs)\r\n",
        "      for sent, labs in zip(sentences, labels)\r\n",
        "    ]\r\n",
        "    tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\r\n",
        "    labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\r\n",
        "    return tokenized_texts, labels"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKmCFaeQlgjg"
      },
      "source": [
        "tokenized_texts, labels = tokenized(sentences,labels)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D65YDbkfxlbD"
      },
      "source": [
        "Kemudian beri padding pada hasil tokenisasi kalimat (input_ids) dan tagnya. Lalu ekstrak attention_masknya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pw9o7K-qO4Zo"
      },
      "source": [
        "def get_input_tags_attention(tokenized_texts, labels, MAX_LEN):\r\n",
        "  input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\r\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\r\n",
        "                          truncating=\"post\", padding=\"post\")\r\n",
        "  tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\r\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\r\n",
        "                     dtype=\"long\", truncating=\"post\")\r\n",
        "  attention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]\r\n",
        "\r\n",
        "  return input_ids, tags, attention_masks"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64AJaGNhPQaW"
      },
      "source": [
        "input_ids, tags, attention_masks = get_input_tags_attention(tokenized_texts, labels, MAX_LEN)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Isn4fx9uxvvq"
      },
      "source": [
        "## Train Val split dan Data Loader\r\n",
        "Melakukan pembagian data, dengan data train 90% dan data validasi 10%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1HGJ8rHluKh"
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\r\n",
        "                                                            random_state=2018, test_size=0.1)\r\n",
        "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\r\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oqR-pIqOW9p"
      },
      "source": [
        "Fungsi tersebut digunakan untuk konversi input_ids, tags, dan masks menjadi bentuk tensor dan load dengan Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puy7_rbClv5e"
      },
      "source": [
        "def data_loader(input_ids, tag, attention_mask, bs):\r\n",
        "  t_inputs = torch.tensor(input_ids)\r\n",
        "  t_tags = torch.tensor(tag)\r\n",
        "  t_masks = torch.tensor(attention_mask)\r\n",
        "\r\n",
        "  data = TensorDataset(t_inputs, t_masks, t_tags)\r\n",
        "  dataloader = DataLoader(data, batch_size=bs)\r\n",
        "\r\n",
        "  return data, dataloader"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvYH3Bwjl7kv"
      },
      "source": [
        "train_data,train_dataloader = data_loader(tr_inputs, tr_tags, tr_masks,bs)\r\n",
        "valid_data,valid_dataloader = data_loader(val_inputs, val_tags, val_masks,bs)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5XtqT8rnPaf"
      },
      "source": [
        "## BERT Model\r\n",
        "Melakukan inisiasi model terlebih dahulu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "cc9510e9a5c94b3d8f0d8fa7556903e8",
            "f97fd85d1e4e47cd93980e61e8dcc7c7",
            "7f3a6d28bd5d4f3ebbd6809b0d9a96c7",
            "5f6b0003fb6e4e5bacaf8634588e74e3",
            "2691d2f090e54f5da090ab248772b258",
            "2a6180aad4fd4b5fb54154c535c05113",
            "224b5987a7524a9584b5590f39b68b7d",
            "d440783ef4534d608f6338098a428605",
            "8e395e9cf61e474d8d299a2635f78f34",
            "d1cbacf7dcc44930aaaf5c26ad7d3108",
            "31b5fe561714457d89e457af173757a0",
            "66d1dfa6194a4a15854e255693008c01",
            "63517e572f9447dfb890f35fe6175aa9",
            "ffa1fbfd56dc44f28ed54fb9aac97ff1",
            "8714962efb064391a9a913aeacb6aaf2",
            "ac231fd44bd74fab82c4833bede98fbe"
          ]
        },
        "id": "wAfL80UYnQh7",
        "outputId": "8092fa98-5dbd-4c86-b092-a5eaf00e45b5"
      },
      "source": [
        "from transformers import DistilBertForTokenClassification\r\n",
        "\r\n",
        "model = DistilBertForTokenClassification.from_pretrained(\r\n",
        "    PRE_TRAINED_MODEL_NAME,\r\n",
        "    num_labels=len(tag2idx),\r\n",
        "    output_attentions = False,\r\n",
        "    output_hidden_states = False\r\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc9510e9a5c94b3d8f0d8fa7556903e8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e395e9cf61e474d8d299a2635f78f34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNa5vhW8nbNs",
        "outputId": "9368ef8f-02d0-49e5-9156-130f7088f345"
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForTokenClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=24, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1FYSUcA6hRh"
      },
      "source": [
        "Kemudian dilakukan set optimizer, scheduler, dan epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPqxJ-C8oDy2"
      },
      "source": [
        "epochs = 5\r\n",
        "\r\n",
        "#set optimizer\r\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "\r\n",
        "#set schedule\r\n",
        "scheduler = get_linear_schedule_with_warmup(\r\n",
        "  optimizer,\r\n",
        "  num_warmup_steps=0,\r\n",
        "  num_training_steps=total_steps\r\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3JhFu9tzHGA"
      },
      "source": [
        "## Model Function\r\n",
        "Berikut ini fungsi training dan fungsi evaluasi yang digunakan untuk proses training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeZVAF9x6uXO"
      },
      "source": [
        "### Fungsi train_epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBmfxaBU_82b"
      },
      "source": [
        "def train_epoch(\r\n",
        "  model, \r\n",
        "  data_loader, \r\n",
        "  optimizer, \r\n",
        "  device, \r\n",
        "  scheduler, \r\n",
        "  n_examples\r\n",
        "):\r\n",
        "  # Put the model into training mode.\r\n",
        "  model.train()\r\n",
        "  # Reset the total loss for this epoch.\r\n",
        "  total_loss = 0\r\n",
        "\r\n",
        "  # Reset the validation loss for this epoch.\r\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "  predictions , true_labels = [], []\r\n",
        "\r\n",
        "  # Training loop\r\n",
        "  for step, batch in enumerate(data_loader):\r\n",
        "      # add batch to gpu\r\n",
        "      batch = tuple(t.to(device) for t in batch)\r\n",
        "      b_input_ids, b_input_mask, b_labels = batch\r\n",
        "      # Always clear any previously calculated gradients before performing a backward pass.\r\n",
        "      model.zero_grad()\r\n",
        "      # forward pass\r\n",
        "      # This will return the loss (rather than the model output)\r\n",
        "      # because we have provided the `labels`.\r\n",
        "      outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\r\n",
        "\r\n",
        "      # Move logits and labels to CPU\r\n",
        "      logits = outputs[1].detach().cpu().numpy()\r\n",
        "      label_ids = b_labels.to('cpu').numpy()\r\n",
        "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\r\n",
        "      true_labels.extend(label_ids)\r\n",
        "\r\n",
        "      # get the loss\r\n",
        "      loss = outputs[0]\r\n",
        "      # Perform a backward pass to calculate the gradients.\r\n",
        "      loss.backward()\r\n",
        "      # track train loss\r\n",
        "      total_loss += loss.item()\r\n",
        "      # Clip the norm of the gradient\r\n",
        "      # This is to help prevent the \"exploding gradients\" problem.\r\n",
        "      torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=1)\r\n",
        "      # update parameters\r\n",
        "      optimizer.step()\r\n",
        "      # Update the learning rate.\r\n",
        "      scheduler.step()\r\n",
        "\r\n",
        "    # Calculate the average loss over the training data.\r\n",
        "  avg_train_loss = total_loss / len(data_loader)\r\n",
        "  pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\r\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\r\n",
        "  valid_tags = [tag_values[l_i] for l in true_labels\r\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\r\n",
        "  return accuracy_score(pred_tags, valid_tags),avg_train_loss"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocZ-mXH06yrM"
      },
      "source": [
        "### Fungsi eval_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2--J2KHBG5n"
      },
      "source": [
        "def eval_model(model, data_loader, device, n_examples):\r\n",
        "\r\n",
        "  # Put the model into evaluation mode\r\n",
        "  model.eval()\r\n",
        "  # Reset the validation loss for this epoch.\r\n",
        "  eval_loss, eval_accuracy = 0, 0\r\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "  predictions , true_labels = [], []\r\n",
        "  \r\n",
        "  for batch in data_loader:\r\n",
        "      batch = tuple(t.to(device) for t in batch)\r\n",
        "      b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "      # Telling the model not to compute or store gradients,\r\n",
        "      # saving memory and speeding up validation\r\n",
        "      with torch.no_grad():\r\n",
        "          # Forward pass, calculate logit predictions.\r\n",
        "          # This will return the logits rather than the loss because we have not provided labels.\r\n",
        "          outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\r\n",
        "\r\n",
        "      # Move logits and labels to CPU\r\n",
        "      logits = outputs[1].detach().cpu().numpy()\r\n",
        "      label_ids = b_labels.to('cpu').numpy()\r\n",
        "\r\n",
        "      # Calculate the accuracy for this batch of test sentences.\r\n",
        "      eval_loss += outputs[0].mean().item()\r\n",
        "      predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\r\n",
        "      true_labels.extend(label_ids)\r\n",
        "\r\n",
        "  eval_loss = eval_loss / len(data_loader)\r\n",
        "  pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\r\n",
        "                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\r\n",
        "  valid_tags = [tag_values[l_i] for l in true_labels\r\n",
        "                                  for l_i in l if tag_values[l_i] != \"PAD\"]\r\n",
        "  return accuracy_score(pred_tags, valid_tags),eval_loss"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKpImqTzAJng"
      },
      "source": [
        "## Proses Training\r\n",
        "Proses training dilakukan pada code berikut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tA0knxTk9ULx",
        "outputId": "b71c36e7-b491-47c0-fbc8-9940be15d677"
      },
      "source": [
        "for epoch in range(epochs):\r\n",
        "\r\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\r\n",
        "    print('-' * 10)\r\n",
        "\r\n",
        "    #memanggil fungsi train epoch\r\n",
        "    train_acc, train_loss = train_epoch(\r\n",
        "      model,\r\n",
        "      train_dataloader,    \r\n",
        "      optimizer, \r\n",
        "      device, \r\n",
        "      scheduler, \r\n",
        "      len(train_data)\r\n",
        "    )\r\n",
        "\r\n",
        "    #mencetak train loss dan accuracy\r\n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\r\n",
        "\r\n",
        "    val_acc, val_loss = eval_model(\r\n",
        "      model,\r\n",
        "      valid_dataloader,    \r\n",
        "      device, \r\n",
        "      len(valid_data)\r\n",
        "    )\r\n",
        "    \r\n",
        "    #mencetak val loss dan accuracy\r\n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\r\n",
        "    print()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "----------\n",
            "Train loss 0.2879372487465541 accuracy 0.9140082855238568\n",
            "Val   loss 0.10778755907501493 accuracy 0.970303814817635\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n",
            "Train loss 0.0765325463864775 accuracy 0.9788854184363797\n",
            "Val   loss 0.10205597975956542 accuracy 0.971712480012183\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n",
            "Train loss 0.049043938269956955 accuracy 0.9869139255174096\n",
            "Val   loss 0.10031385999172926 accuracy 0.9736160816264372\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n",
            "Train loss 0.03559629441357203 accuracy 0.9906776966069429\n",
            "Val   loss 0.10144184130643095 accuracy 0.9748343866595599\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n",
            "Train loss 0.029733879135049407 accuracy 0.9922807842932256\n",
            "Val   loss 0.1006661986133882 accuracy 0.9754435391761213\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8dMtTLP39kl"
      },
      "source": [
        "## Pengujian dengan data test\r\n",
        "Setelah proses training, dilakukan evaluasi pada data testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm6jgIDGKemi"
      },
      "source": [
        "### Preprocessing dan Data Loader untuk data test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxuMmLwTaKI"
      },
      "source": [
        "tokenized_texts_test, labels_test = tokenized(sentences_test,labels_test)\r\n",
        "input_ids_test, tags_test, attention_masks_test = get_input_tags_attention(tokenized_texts_test, labels_test, MAX_LEN)\r\n",
        "test_data,test_dataloader = data_loader(input_ids_test, tags_test, attention_masks_test,bs)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf_Wb4ypKjeW"
      },
      "source": [
        "### Evaluasi train, validasi, dan test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3cD_a5053fW"
      },
      "source": [
        "train_acc, train_loss = eval_model(\r\n",
        "      model,\r\n",
        "      train_dataloader,    \r\n",
        "      device, \r\n",
        "      len(train_data)\r\n",
        ")\r\n",
        "val_acc, val_loss = eval_model(\r\n",
        "      model,\r\n",
        "      valid_dataloader,    \r\n",
        "      device, \r\n",
        "      len(valid_data)\r\n",
        ")\r\n",
        "test_acc, test_loss = eval_model(\r\n",
        "      model,\r\n",
        "      test_dataloader,    \r\n",
        "      device, \r\n",
        "      len(test_data)\r\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MHqQtPO6E_t",
        "outputId": "c8fff546-04a9-45dc-9fa1-a34959f3dfa6"
      },
      "source": [
        "print(\"Akurasi training : \", train_acc)\r\n",
        "print(\"Akurasi validasi : \", val_acc)\r\n",
        "print(\"Akurasi test     : \", test_acc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akurasi training :  0.99541726020117\n",
            "Akurasi validasi :  0.9754435391761213\n",
            "Akurasi test     :  0.9735114174924602\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}